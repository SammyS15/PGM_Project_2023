{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb903766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(51945) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import sncosmo\n",
    "import os\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "from read_yse_ztf_snana_dir import read_YSE_ZTF_snana_dir\n",
    "import light_curve\n",
    "from light_curve import VillarFit\n",
    "import extinction\n",
    "from extinction import fm07, apply, remove\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from decimal import Decimal, ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599d566",
   "metadata": {},
   "source": [
    "# Setting up Sims in the same format as Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03251d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_snana_fits(dir_path):\n",
    "    snid_list = []\n",
    "    meta_list = []\n",
    "    yse_ztf_fp_df_list = []\n",
    "    meta = {}\n",
    "    objid = \"\"\n",
    "    if (dir_path == \"../Retrain_RAPID/for_YSE/data/PALEO_YSE_MODEL43_CCSNe_V19_yselc_v2_52LCs\"):\n",
    "        objid = \"yselc_v2\"\n",
    "    elif (dir_path == \"../../../yse_ztf_sims/PALEO_YSE_ZTF_MODEL01\"): #WILL NEED TO UPDATE FOR LOCAL MACHINE\n",
    "        objid = \"SNIa\" #Change if you need other version \n",
    "    elif (dir_path == \"/Users/sammysharief/Downloads/YSE_DR1_SIMS_60k_SNR4_grizXY_SIMLIB_FLUXCALERR_COR_220427/PALEO_YSE_ZTF_MODEL37\"):\n",
    "        objid = \"SNIbc\"\n",
    "    elif (dir_path == \"/Users/sammysharief/Downloads/YSE_DR1_SIMS_60k_SNR4_grizXY_SIMLIB_FLUXCALERR_COR_220427/PALEO_YSE_ZTF_MODEL20\"):\n",
    "        objid = \"SNII\"\n",
    "        \n",
    "    heads = sorted(glob.glob(os.path.join(dir_path, '*_HEAD.FITS.gz')))\n",
    "    phots = sorted(glob.glob(os.path.join(dir_path, '*_PHOT.FITS.gz')))\n",
    "    assert len(heads) != 0, 'no *_HEAD_FITS.gz are found'\n",
    "    assert len(heads) == len(phots), 'there are different number of HEAD and PHOT files'\n",
    "    \n",
    "    for head, phot in zip(heads, phots): #lots of LCs per head, phot files, so do a few to start\n",
    "        i = head.find('_HEAD.FITS.gz')\n",
    "        assert head[:i] == phot[:i], f'HEAD and PHOT files name mismatch: {head}, {phot}'\n",
    "        filename = head[:i].split('/')[-1].split('.')[0]\n",
    "        head_title = head[88:92]         \n",
    "        for LCnum, lc in enumerate(sncosmo.read_snana_fits(head, phot)): # remember: multiple SN in single HEAD/PHOT file\n",
    "            lc.meta['redshift'] = lc.meta['SIM_REDSHIFT_HOST']\n",
    "            redshift = lc.meta['redshift']\n",
    "            checkSnid = lc.meta['SNID']\n",
    "            checkSnid = checkSnid.decode('UTF-8')\n",
    "            redshift = np.round(redshift, 2)\n",
    "            ra = lc.meta['RA']\n",
    "            dec = lc.meta['DEC']\n",
    "            \n",
    "            lc.keep_columns(['MJD', 'BAND', 'FLUXCAL', 'FLUXCALERR', 'PHOTFLAG'])\n",
    "            \n",
    "            totalResidual = 0\n",
    "            fitNew = []\n",
    "            # Astropy Table --> Pandas df\n",
    "            df = lc.to_pandas()\n",
    "            df = df.rename(columns={\n",
    "                \"BAND\": \"PASSBAND\", \n",
    "                \"FLUXCAL\": \"FLUX\",\n",
    "                \"FLUXCALERR\": \"FLUXERR\", \n",
    "                \"PHOTFLAG\": \"PHOTFLAG\"\n",
    "            })\n",
    "            \n",
    "            df['PASSBAND']= df['PASSBAND'].str.decode(\"utf-8\") # turn Bytes into str\n",
    "            snr = []\n",
    "            magerr = []\n",
    "            \n",
    "            snr = df['FLUX']/df['FLUXERR'] \n",
    "            df['MAG'] = np.array(-2.5*np.log10(np.abs(df['FLUX'])))+27.5\n",
    "            magerr = 1.086/snr\n",
    "            df['MAGERR'] = magerr\n",
    "            #Made DF and have all the info\n",
    "            meta['object_id'] = objid\n",
    "            meta['RA'] = ra\n",
    "            meta['DEC'] = dec\n",
    "            meta['redshift'] = redshift\n",
    "            meta['SNID'] = checkSnid\n",
    "            meta['Head'] = head_title\n",
    "            #Add data to respective data structure\n",
    "            snid_list.append(objid)\n",
    "            meta_copy = meta.copy()\n",
    "            meta_list.append(meta_copy)\n",
    "            yse_ztf_fp_df_list.append(df)\n",
    "    return snid_list, meta_list, yse_ztf_fp_df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85de02f",
   "metadata": {},
   "source": [
    "# Plotting YSE DR1 Object and Closest Simulated Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d329991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT UP READING AND PLOTTING\n",
    "#Photflag --> remove rows that photflag == 0 \n",
    "def plotData(snid_list, meta_list, yse_ztf_fp_df_list, plotType, thresehold):\n",
    "    mcmc_niter=(4096)\n",
    "    lmsder_niter=64\n",
    "    fit = VillarFit('mcmc-lmsder', mcmc_niter=mcmc_niter, lmsder_niter=lmsder_niter) #increase mcmc_niter if fits are not good\n",
    "    print(plotType)\n",
    "    print(thresehold)\n",
    "    df = pd.DataFrame()   \n",
    "    mebvExist = 0\n",
    "    num_of_bands = 0\n",
    "    no_points_to_plot_mag = 0\n",
    "    no_points_to_plot_flux = 0\n",
    "    title = \"\"\n",
    "    if (meta_list[0]['object_id'][0] == '2'):\n",
    "        title = f'Real_Data_{plotType}'\n",
    "        mebvExist = 1\n",
    "    else:\n",
    "        title =  f'{snid_list[0]}_{plotType}_sims'\n",
    "\n",
    "    #print(\"title: \", title)\n",
    "    with PdfPages(f'{title}.pdf') as pdf:\n",
    "        for ix, df in enumerate(yse_ztf_fp_df_list):\n",
    "            if (mebvExist == 1):\n",
    "                objid = snid_list[ix]\n",
    "            else:\n",
    "                head = meta_list[ix]['Head']\n",
    "                uniqueObjId = meta_list[ix]['SNID']\n",
    "                objid = f'{head}_{uniqueObjId}_SNIa' #Update if not SN Ia\n",
    "                #print(objid)\n",
    "            df = df.reset_index(drop=True)\n",
    "            \n",
    "            df['SNR'] = df['FLUX']/df['FLUXERR'] \n",
    "            redshift = meta_list[ix]['redshift']\n",
    "            if (redshift < 0):\n",
    "                redshift = \"N/A\"\n",
    "            peakMJD = df.iloc[df['FLUX'].idxmax()][\"MJD\"] \n",
    "            for i in df['MJD']:\n",
    "                if ( np.abs(peakMJD - i) > 200):\n",
    "                    df.drop(df.index[df['MJD'] == i], inplace=True)\n",
    "            if (mebvExist == 1):\n",
    "                D_id_color = {\"X\": u\"olivedrab\",\n",
    "                  \"Y\": u\"darkred\",\n",
    "                  \"g\": u\"g\", \n",
    "                  \"r\": u\"r\",\n",
    "                  \"i\": u\"m\",\n",
    "                  \"z\": u\"k\"}\n",
    "            else:\n",
    "                D_id_color = {\n",
    "                      \"X \": u\"olivedrab\",\n",
    "                      \"Y \": u\"darkred\",\n",
    "                      \"g \": u\"g\", \n",
    "                      \"r \": u\"r\",\n",
    "                      \"i \": u\"m\",\n",
    "                      \"z \": u\"k\"}\n",
    "\n",
    "            df['PLOTCOLOR'] = df.PASSBAND.map(D_id_color)\n",
    "            results_pb, models_pb = [], []\n",
    "            totalResidual = 0\n",
    "            passband = df['PASSBAND']\n",
    "            count = 0\n",
    "            countPlot = 0\n",
    "            noFitDf = df.copy()\n",
    "            if (plotType == \"MAG\"):\n",
    "                plt.gca().invert_yaxis()\n",
    "            if (ix == -10): #change ix if you need to debug and don't wanna take forever\n",
    "                break\n",
    "            for pb in np.unique(passband):\n",
    "                mask = (df['PASSBAND'] == pb) & (df['PHOTFLAG'] != 0) & (df['SNR'] > 4) & (df['FLUX'] > 0)#no non-detections\n",
    "                df_pb = df[mask] \n",
    "                df_pb = df_pb.sort_values(by=['MJD'], ascending=True) # w/ photpipe, some have (near) duplicate MJDs separated\n",
    "                df_pb = df_pb.drop_duplicates(subset=['MJD']) # Remove all duplicate MJD rows (prob w/ photpipe output)    \n",
    "                mjd_pb = np.array(df_pb['MJD'])\n",
    "                mag_pb = np.array(df_pb['MAG'])\n",
    "                magerr_pb = np.array(df_pb['MAGERR'])\n",
    "                flux_pb = np.array(df_pb['FLUX'])\n",
    "                fluxerr_pb = np.array(df_pb['FLUXERR'])\n",
    "                passband_pb = np.array(df_pb['PASSBAND'])\n",
    "                photflag_pb = np.array(df_pb['PHOTFLAG'])\n",
    "                plotcolor_pb = df_pb['PLOTCOLOR'] \n",
    "                if (len(mjd_pb) < 8):\n",
    "                    df_pb.drop(df_pb.index[df_pb['PASSBAND'] == pb], inplace=True)\n",
    "                    count = count + 1\n",
    "                    continue\n",
    "                else:\n",
    "                    mjd_pb = np.float64(mjd_pb)\n",
    "                    flux_pb = np.float64(flux_pb)\n",
    "                    fluxerr_pb = np.float64(fluxerr_pb)\n",
    "                    result_pb = fit(mjd_pb, flux_pb, fluxerr_pb, sorted=True) #sorted=True now b/c we use sort_value\n",
    "                    results_pb.append(result_pb)\n",
    "                    max_mjd_pb = np.max(mjd_pb)\n",
    "                    min_mjd_pb = np.min(mjd_pb)\n",
    "                    day0p1 = (max_mjd_pb-min_mjd_pb)/0.1\n",
    "                    mjd_grid_pb = np.linspace(min_mjd_pb, max_mjd_pb, int(day0p1))\n",
    "                    # Minimum number of observations: **8** per band to plot\n",
    "                    model_pb = VillarFit.model(mjd_grid_pb, result_pb)\n",
    "                    models_pb.append(model_pb)\n",
    "                    #Villar fit on actual mjd data so you have the same amount of data points\n",
    "                    model_pbNew = VillarFit.model(mjd_pb, result_pb) #Just using actual data --> It gives it to you in flux\n",
    "                    model_pbMagNew = np.array(-2.5*np.log10(np.abs(model_pbNew)))+27.5 #Converting to Mag\n",
    "                    #Residuals = np.abs(mag - model_pbMagNew)\n",
    "                    Residuals_pb = np.abs(mag_pb - model_pbMagNew)\n",
    "                    #Residuals = np.abs((flux - model_pbNew)/fluxerr)\n",
    "                    df_pb['Residuals'] = np.array(Residuals_pb)\n",
    "                    if not os.path.exists(f'../Photpipe/yse_ztf_fp_VillarFit_noNonDetect_flux_mcmc_niter={mcmc_niter}_lmsder_niter={lmsder_niter}'):\n",
    "                        os.makedirs(f'../Photpipe/yse_ztf_fp_VillarFit_noNonDetect_flux_mcmc_niter={mcmc_niter}_lmsder_niter={lmsder_niter}')\n",
    "                    \n",
    "                    plt.xlabel('MJD')\n",
    "                    if (plotType == 'FLUX'):\n",
    "                        if plt.gca().yaxis_inverted():\n",
    "                            plt.gca().invert_yaxis()\n",
    "                        #Flux\n",
    "                        plt.ylabel('FLUX')\n",
    "                        plt.errorbar(mjd_pb, flux_pb, fluxerr_pb, alpha=0.7, fmt='o', c=np.unique(plotcolor_pb)[0], label=pb)\n",
    "                        plt.plot(mjd_grid_pb, model_pb, linestyle='dashed', \n",
    "                             linewidth=2.5, alpha=0.9, c=np.unique(plotcolor_pb)[0], label=f'{pb}-fit')\n",
    "                    else:\n",
    "                        #Mag\n",
    "                        plt.ylabel('MAG')\n",
    "                        if plt.gca().yaxis_inverted():\n",
    "                            plt.errorbar(mjd_pb, mag_pb, magerr_pb, alpha=0.7, fmt='o', c=np.unique(plotcolor_pb)[0], label=pb)\n",
    "                        else:\n",
    "                            plt.gca().invert_yaxis()\n",
    "                            plt.errorbar(mjd_pb, mag_pb, magerr_pb, alpha=0.7, fmt='o', c=np.unique(plotcolor_pb)[0], label=pb)\n",
    "                    if (type(redshift) == str):\n",
    "                        redshift = \"N/A\"\n",
    "                        plt.title(f'{objid}, z={redshift}, #residuals > 0.5 mag={totalResidual}')\n",
    "                    else: \n",
    "                        redshift <= 0\n",
    "                        plt.title(f'{objid}, z={str(round(redshift, 3))}, #residuals > 0.5 mag={totalResidual}')\n",
    "                    plt.legend(loc='upper right', bbox_to_anchor=(1, 1), ncol=2, fancybox=True, shadow=False)\n",
    "                if (len(df_pb[\"Residuals\"]) > 0):\n",
    "                    dfResiduals = df_pb[df_pb[\"Residuals\"] >= thresehold]\n",
    "                    if (len(dfResiduals) != 0):\n",
    "                        Rpassband = dfResiduals['PASSBAND']\n",
    "                        for pb in np.unique(Rpassband):\n",
    "                            mask = (dfResiduals['PASSBAND'] == pb) & (dfResiduals['PHOTFLAG'] != 0) & (dfResiduals['SNR'] > 4) & (dfResiduals['FLUX'] > 0) #no non-detections\n",
    "                            Rdf_pb = dfResiduals[mask] \n",
    "                            Rdf_pb = Rdf_pb.sort_values(by=['MJD'], ascending=True) # w/ photpipe, some have (near) duplicate MJDs separated\n",
    "                            Rdf_pb = Rdf_pb.drop_duplicates(subset=['MJD']) # Remove all duplicate MJD rows (prob w/ photpipe output)    \n",
    "\n",
    "                            Rmjd_pb = np.array(Rdf_pb['MJD'])\n",
    "                            Rmag_pb = np.array(Rdf_pb['MAG'])\n",
    "                            Rmagerr_pb = np.array(Rdf_pb['MAGERR'])\n",
    "                            Rflux_pb = np.array(Rdf_pb['FLUX'])\n",
    "                            Rfluxerr_pb = np.array(Rdf_pb['FLUXERR'])\n",
    "                            passband_pb = np.array(Rdf_pb['PASSBAND'])\n",
    "                            photflag_pb = np.array(Rdf_pb['PHOTFLAG'])\n",
    "                            plotcolor_pb = Rdf_pb['PLOTCOLOR']\n",
    "\n",
    "                            if (plotType == \"FLUX\"):\n",
    "                                if plt.gca().yaxis_inverted():\n",
    "                                    plt.gca().invert_yaxis()\n",
    "                                plt.errorbar(Rmjd_pb, Rflux_pb, Rfluxerr_pb, alpha=0.7, fmt='X', c=\"yellow\")\n",
    "                            else:\n",
    "                                if plt.gca().yaxis_inverted():\n",
    "                                    plt.errorbar(Rmjd_pb, Rmag_pb, Rmagerr_pb, alpha=0.7, fmt='X', c=\"yellow\")\n",
    "                                else:\n",
    "                                    plt.gca().invert_yaxis()\n",
    "                                    plt.errorbar(Rmjd_pb, Rmag_pb, Rmagerr_pb, alpha=0.7, fmt='X', c=\"yellow\")\n",
    "                        totalResidual = totalResidual + len(dfResiduals)\n",
    "                if (type(redshift) == str):\n",
    "                    redshift = \"N/A\"\n",
    "                    plt.title(f'{objid}, z={redshift}, #residuals > 0.5 mag={totalResidual}')\n",
    "                else: \n",
    "                    redshift <= 0\n",
    "                    plt.title(f'{objid}, z={str(round(redshift, 3))}, #residuals > 0.5 mag={totalResidual}')\n",
    "                plt.legend(loc='upper right', bbox_to_anchor=(1, 1), ncol=2, fancybox=True, shadow=False)\n",
    "            if (count == len(np.unique(passband))):\n",
    "                num_of_bands = 0\n",
    "                no_points_to_plot_mag = 0\n",
    "                no_points_to_plot_flux = 0\n",
    "                passband = noFitDf['PASSBAND']\n",
    "                for pb in np.unique(passband):\n",
    "                    num_of_bands = num_of_bands + 1\n",
    "                    mask = (noFitDf['PASSBAND'] == pb) & (noFitDf['PHOTFLAG'] != 0) & (noFitDf['SNR'] > 4) & (noFitDf['FLUX'] > 0) #no non-detections\n",
    "                    Rdf_pb = noFitDf[mask] \n",
    "                    Rdf_pb = Rdf_pb.sort_values(by=['MJD'], ascending=True) # w/ photpipe, some have (near) duplicate MJDs separated\n",
    "                    Rdf_pb = Rdf_pb.drop_duplicates(subset=['MJD']) # Remove all duplicate MJD rows (prob w/ photpipe output)    \n",
    "                    Rmjd_pb = np.array(Rdf_pb['MJD'])\n",
    "                    Rmag_pb = np.array(Rdf_pb['MAG'])\n",
    "                    Rmagerr_pb = np.array(Rdf_pb['MAGERR'])\n",
    "                    Rflux_pb = np.array(Rdf_pb['FLUX'])\n",
    "                    Rfluxerr_pb = np.array(Rdf_pb['FLUXERR'])\n",
    "                    passband_pb = np.array(Rdf_pb['PASSBAND'])\n",
    "                    photflag_pb = np.array(Rdf_pb['PHOTFLAG'])\n",
    "                    plotcolor_pb = Rdf_pb['PLOTCOLOR']\n",
    "                    \n",
    "                    #FLux V Mag plots\n",
    "                    if (plotType == \"FLUX\"):\n",
    "                        if plt.gca().yaxis_inverted():\n",
    "                            plt.gca().invert_yaxis()\n",
    "                        if (len(noFitDf[mask]) == 0):\n",
    "                            no_points_to_plot_flux = no_points_to_plot_flux + 1\n",
    "                            continue\n",
    "                        plt.errorbar(Rmjd_pb, Rflux_pb, Rfluxerr_pb, alpha=0.7, fmt='o',c=np.unique(plotcolor_pb)[0], label=pb)\n",
    "                        plt.legend(loc='upper right', bbox_to_anchor=(1, 1), ncol=2, fancybox=True, shadow=False)\n",
    "                    else:\n",
    "                        if (len(noFitDf[mask]) == 0):\n",
    "                            no_points_to_plot_mag = no_points_to_plot_mag + 1\n",
    "                        else:\n",
    "                            if plt.gca().yaxis_inverted():\n",
    "                                plt.errorbar(Rmjd_pb, Rmag_pb, Rmagerr_pb, alpha=0.7, fmt='o', c=np.unique(plotcolor_pb)[0], label=pb)\n",
    "                                plt.legend(loc='upper right', bbox_to_anchor=(1, 1), ncol=2, fancybox=True, shadow=False)\n",
    "                            else: \n",
    "                                plt.gca().invert_yaxis()\n",
    "                                plt.errorbar(Rmjd_pb, Rmag_pb, Rmagerr_pb, alpha=0.7, fmt='o', c=np.unique(plotcolor_pb)[0], label=pb)\n",
    "                                plt.legend(loc='upper right', bbox_to_anchor=(1, 1), ncol=2, fancybox=True, shadow=False)\n",
    "                #Edge case on redshift type\n",
    "                if (type(redshift) == str):\n",
    "                    redshift = \"N/A\"\n",
    "                    plt.title(f'{objid}, z={redshift}')\n",
    "                else: \n",
    "                    redshift <= 0\n",
    "                    plt.title(f'{objid}, z={str(round(redshift, 3))}')\n",
    "\n",
    "            if ( (num_of_bands == no_points_to_plot_mag) or (num_of_bands == no_points_to_plot_flux) ):\n",
    "                num_of_bands = 1\n",
    "                no_points_to_plot_mag = 0\n",
    "                no_points_to_plot_flux = 0\n",
    "                continue\n",
    "            pdf.savefig()  # saves the current figure into a pdf page\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1ef1e",
   "metadata": {},
   "source": [
    "# CSV FUNCTION NOT PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fad0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create df for ZTF g band and ZTF y band and then store it in a csv \n",
    "import pandas as pd\n",
    "def csvFunction(snid_list, meta_list, yse_ztf_fp_df_list):\n",
    "    mcmc_niter=(4096)\n",
    "    lmsder_niter=64\n",
    "    fit = VillarFit('mcmc-lmsder', mcmc_niter=mcmc_niter, lmsder_niter=lmsder_niter) #increase mcmc_niter if fits are not good\n",
    "    df = pd.DataFrame()   \n",
    "    mebvExist = 0\n",
    "    objid = \"\"\n",
    "    flux_pb_list, flux_corr_pb_list = [],[]\n",
    "    #var to check if we are dealing with real or sim since the data we pass is a lil different\n",
    "    #1 means real\n",
    "    #0 means sim\n",
    "    check = 0 \n",
    "    csvTitle = \"\"\n",
    "    if (meta_list[0]['object_id'][0] == '2'):\n",
    "        print(\"REAL DATA\")\n",
    "        csvTitle = \"Real_Data\"\n",
    "        check = 1\n",
    "    else:\n",
    "        type_of_sn = snid_list[0]\n",
    "        csvTitle =  f'{snid_list[0]}_sims'\n",
    "  \n",
    "    # Define column names\n",
    "    column_names = ['ObjectID', 'X_villar_fit_amplitude', 'X_villar_fit_baseline',\n",
    "                    'X_villar_fit_peak_time', 'X_villar_fit_rise_time',\n",
    "                    'X_villar_fit_fall_time', 'X_villar_fit_plateau_slope',\n",
    "                    'X_villar_fit_plateau_duration', 'X_villar_fit_reduced_chi2',\n",
    "                    'Y_villar_fit_amplitude', 'Y_villar_fit_baseline',\n",
    "                    'Y_villar_fit_peak_time', 'Y_villar_fit_rise_time',\n",
    "                    'Y_villar_fit_fall_time', 'Y_villar_fit_plateau_slope',\n",
    "                    'Y_villar_fit_plateau_duration', 'Y_villar_fit_reduced_chi2']\n",
    "\n",
    "    # Initialize dataCSV as an empty DataFrame with NaN values\n",
    "    dataCSV = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    # Create a row with NaN values\n",
    "    nan_row = {col: np.nan for col in column_names}\n",
    "\n",
    "    row_to_append = pd.DataFrame([nan_row], columns=column_names)\n",
    "\n",
    "    print('datacsv: ', type(dataCSV))\n",
    "    dataCSV = pd.concat([dataCSV, pd.DataFrame([nan_row], columns=column_names)], ignore_index=True)\n",
    "    \n",
    "    for ix, df in enumerate(yse_ztf_fp_df_list):\n",
    "        resultList = []\n",
    "        if(check == 1):\n",
    "            objid = snid_list[ix]\n",
    "            # print(objid)\n",
    "            resultList.append(objid)\n",
    "        else:\n",
    "            head = meta_list[ix]['Head']\n",
    "            uniqueObjId = meta_list[ix]['SNID']\n",
    "            objid = f'{head}_{uniqueObjId}_{type_of_sn}' #Update if not SN Ia\n",
    "            resultList.append(objid) \n",
    "        # if (check == 1):\n",
    "            #Checking to see if we are looking at real data type SNIa else skip\n",
    "            #Update if not SN Ia\n",
    "            # if (meta_list[ix]['spectype_3class'] != 'SNIa'):\n",
    "                # continue\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['SNR'] = df['FLUX']/df['FLUXERR'] \n",
    "        redshift = meta_list[ix]['redshift']\n",
    "        if (redshift < 0):\n",
    "            redshift = \"N/A\"\n",
    "        peakMJD = df.iloc[df['FLUX'].idxmax()][\"MJD\"] \n",
    "        for i in df['MJD']:\n",
    "            if ( np.abs(peakMJD - i) > 200):\n",
    "                df.drop(df.index[df['MJD'] == i], inplace=True)\n",
    "        if (mebvExist == 1):\n",
    "            D_id_color = {\"X\": u\"olivedrab\",\n",
    "              \"Y\": u\"darkred\",\n",
    "              \"g\": u\"g\", \n",
    "              \"r\": u\"r\",\n",
    "              \"i\": u\"m\",\n",
    "              \"z\": u\"k\"}\n",
    "        else:\n",
    "            D_id_color = {\n",
    "                  \"X \": u\"olivedrab\",\n",
    "                  \"Y \": u\"darkred\",\n",
    "                  \"g \": u\"g\", \n",
    "                  \"r \": u\"r\",\n",
    "                  \"i \": u\"m\",\n",
    "                  \"z \": u\"k\"}\n",
    "\n",
    "        df['PLOTCOLOR'] = df.PASSBAND.map(D_id_color)\n",
    "        results_pb, models_pb = [], []\n",
    "        totalResidual = 0\n",
    "        passband = df['PASSBAND']\n",
    "        count = 0\n",
    "        countPlot = 0\n",
    "        noFitDf = df.copy()\n",
    "        countNum = 0\n",
    "        if (ix == -1):\n",
    "            break\n",
    "        for pb in np.unique(passband):\n",
    "            mask = (df['PASSBAND'] == pb) & (df['PHOTFLAG'] != 0) & (df['SNR'] > 4) & (df['FLUX'] > 0)#no non-detections\n",
    "\n",
    "            df_pb = df[mask] \n",
    "            df_pb = df_pb.sort_values(by=['MJD'], ascending=True) # w/ photpipe, some have (near) duplicate MJDs separated\n",
    "            df_pb = df_pb.drop_duplicates(subset=['MJD']) # Remove all duplicate MJD rows (prob w/ photpipe output)    \n",
    "\n",
    "            mjd_pb = np.array(df_pb['MJD'])\n",
    "            mag_pb = np.array(df_pb['MAG'])\n",
    "            magerr_pb = np.array(df_pb['MAGERR'])\n",
    "            flux_pb = np.array(df_pb['FLUX'])\n",
    "            fluxerr_pb = np.array(df_pb['FLUXERR'])\n",
    "            passband_pb = np.array(df_pb['PASSBAND'])\n",
    "            photflag_pb = np.array(df_pb['PHOTFLAG'])\n",
    "            plotcolor_pb = df_pb['PLOTCOLOR'] \n",
    "            if (len(mjd_pb) < 8):\n",
    "                count = count + 1\n",
    "                continue\n",
    "            else:\n",
    "                mjd_pb = np.float64(mjd_pb)\n",
    "                flux_pb = np.float64(flux_pb)\n",
    "                fluxerr_pb = np.float64(fluxerr_pb)\n",
    "                result_pb = fit(mjd_pb, flux_pb, fluxerr_pb, sorted=True) #sorted=True now b/c we use sort_value\n",
    "                results_pb.append(result_pb)\n",
    "\n",
    "                if (pb == \"X \" or pb == \"X\"):\n",
    "                    if (len(resultList) == 1):\n",
    "                        for i in range(0, len(result_pb)):\n",
    "                            resultList.append(result_pb[i])\n",
    "\n",
    "\n",
    "                if (pb == \"Y \" or pb == \"Y\"):\n",
    "                    for i in range(0, len(result_pb)):\n",
    "                        resultList.append(result_pb[i])\n",
    "        if (len(resultList) == 17):\n",
    "            row_to_append = pd.DataFrame({'ObjectID': [resultList[0]],\n",
    "                                        'X_villar_fit_amplitude': [resultList[1]],\n",
    "                                        'X_villar_fit_baseline': [resultList[2]],\n",
    "                                        'X_villar_fit_peak_time': [resultList[3]],\n",
    "                                        'X_villar_fit_rise_time': [resultList[4]],\n",
    "                                        'X_villar_fit_fall_time': [resultList[5]],\n",
    "                                        'X_villar_fit_plateau_slope': [resultList[6]],\n",
    "                                        'X_villar_fit_plateau_duration': [resultList[7]],\n",
    "                                        'X_villar_fit_reduced_chi2': [resultList[8]],\n",
    "                                        'Y_villar_fit_amplitude': [resultList[9]],\n",
    "                                        'Y_villar_fit_baseline': [resultList[10]],\n",
    "                                        'Y_villar_fit_peak_time': [resultList[11]],\n",
    "                                        'Y_villar_fit_rise_time': [resultList[12]],\n",
    "                                        'Y_villar_fit_fall_time': [resultList[13]],\n",
    "                                        'Y_villar_fit_plateau_slope': [resultList[14]],\n",
    "                                        'Y_villar_fit_plateau_duration': [resultList[15]],\n",
    "                                        'Y_villar_fit_reduced_chi2': [resultList[16]]})\n",
    "            dataCSV = pd.concat([dataCSV, row_to_append], ignore_index=True)\n",
    "    dataCSV = dataCSV.iloc[1:]\n",
    "    \n",
    "    print(\"CSV TITLE: \", csvTitle)\n",
    "    dataCSV.to_csv(f'{csvTitle}.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b78a2",
   "metadata": {},
   "source": [
    "# Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078495a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS REAL DATA, format is th same for sim\n",
    "snid_list, meta_list, yse_ztf_fp_df_list = read_YSE_ZTF_snana_dir(dir_name='spec_yse_dr1') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ab8b8",
   "metadata": {},
   "source": [
    "# CSV For Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57a96b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL DATA\n",
      "datacsv:  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jv/k_v96nss5g52chcq2phrbl240000gn/T/ipykernel_24073/2191943403.py:148: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataCSV = pd.concat([dataCSV, row_to_append], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV TITLE:  Real_Data\n"
     ]
    }
   ],
   "source": [
    "#snid_list, meta_list, yse_ztf_fp_df_list is already defined\n",
    "csvFunction(snid_list, meta_list, yse_ztf_fp_df_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df45b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(snid_list)\n",
    "# for ix, df in enumerate(yse_ztf_fp_df_list):\n",
    "#     redshift = meta_list[ix]['redshift']\n",
    "#     print(redshift)\n",
    "#     print(type(redshift))\n",
    "#     if (redshift < 0):\n",
    "#         redshift = \"N/A\"\n",
    "#         print(\"new redshift: \", redshift)\n",
    "#snid_list[0]\n",
    "# print(snid_list[0])\n",
    "# print(meta_list[0])\n",
    "# print(yse_ztf_fp_df_list[0])\n",
    "\n",
    "\n",
    "# meta_list[0]['object_id'][0]\n",
    "# meta_list[0]['num_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf85a02",
   "metadata": {},
   "source": [
    "# Flux for Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc34a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#snid_list, meta_list, yse_ztf_fp_df_list is already defined. Change thresehold to your needs\n",
    "#This is purely for FLUX\n",
    "plotData(snid_list, meta_list, yse_ztf_fp_df_list, plotType = \"FLUX\", thresehold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae603937",
   "metadata": {},
   "source": [
    "# Mag for Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6717d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#snid_list, meta_list, yse_ztf_fp_df_list is already defined. Change thresehold to your needs\n",
    "#This is purely for MAG\n",
    "plotData(snid_list, meta_list, yse_ztf_fp_df_list, plotType = \"MAG\", thresehold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672e48d",
   "metadata": {},
   "source": [
    "# Sim SNIA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8331fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sammysharief/anaconda3/envs/pgm_project/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/sammysharief/anaconda3/envs/pgm_project/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#SIMS\n",
    "#WILL NEED TO CHANGE DIR PATH TO WHEREVER SIMS ARE LOCATED ON YOUR MACHINE\n",
    "#Update if not SN Ia\n",
    "snid_list, meta_list, yse_ztf_fp_df_list = read_snana_fits(dir_path='/Users/sammysharief/Downloads/YSE_DR1_SIMS_60k_SNR4_grizXY_SIMLIB_FLUXCALERR_COR_220427/PALEO_YSE_ZTF_MODEL20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac6c11",
   "metadata": {},
   "source": [
    "# CSV for SNIa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5da1b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datacsv:  <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jv/k_v96nss5g52chcq2phrbl240000gn/T/ipykernel_18651/3318573224.py:146: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataCSV = pd.concat([dataCSV, row_to_append], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV TITLE:  SNII_sims\n"
     ]
    }
   ],
   "source": [
    "#snid_list, meta_list, yse_ztf_fp_df_list is already defined\n",
    "csvFunction(snid_list, meta_list, yse_ztf_fp_df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb880a",
   "metadata": {},
   "source": [
    "# Flux plotting for SNIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#snid_list, meta_list, yse_ztf_fp_df_list is already defined. Change thresehold to your needs\n",
    "#This is purely for FLUX\n",
    "plotData(snid_list, meta_list, yse_ztf_fp_df_list, plotType = \"FLUX\", thresehold = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00039f6",
   "metadata": {},
   "source": [
    "# Mag plotting for SNIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbc1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#snid_list, meta_list, yse_ztf_fp_df_list is already defined. Change thresehold to your needs\n",
    "#This is purely for MAG\n",
    "plotData(snid_list, meta_list, yse_ztf_fp_df_list, plotType = \"MAG\", thresehold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ecb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing Old Code\n",
    "  #Define all the columm names\n",
    "    # dataCSV = pd.DataFrame(columns = ['ObjectID', 'X_villar_fit_amplitude', 'X_villar_fit_baseline', \n",
    "    #                                   'X_villar_fit_peak_time', 'X_villar_fit_rise_time', \n",
    "    #                                   'X_villar_fit_fall_time', 'X_villar_fit_plateau_slope', \n",
    "    #                                   'X_villar_fit_plateau_duration', 'X_villar_fit_reduced_chi2', \n",
    "    #                                   'Y_villar_fit_amplitude', 'Y_villar_fit_baseline', \n",
    "    #                                   'Y_villar_fit_peak_time', 'Y_villar_fit_rise_time', \n",
    "    #                                   'Y_villar_fit_fall_time', 'Y_villar_fit_plateau_slope', \n",
    "    #                                   'Y_villar_fit_plateau_duration', 'Y_villar_fit_reduced_chi2'])\n",
    "    # #In case Ztf g or Ztf r does not \"exist\" --> If both don't exist we skip\n",
    "    # nA = [\"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"]\n",
    "    # #Define what var goes to what column\n",
    "    # dataCSV = dataCSV.append({'ObjectID' : np.nan, \n",
    "    #                       'X_villar_fit_amplitude' : np.nan, \n",
    "    #                       'X_villar_fit_baseline' : np.nan, \n",
    "    #                       'X_villar_fit_peak_time' : np.nan, \n",
    "    #                       'X_villar_fit_rise_time' : np.nan, \n",
    "    #                       'X_villar_fit_fall_time' : np.nan, \n",
    "    #                       'X_villar_fit_plateau_slope' : np.nan, \n",
    "    #                       'X_villar_fit_plateau_duration' : np.nan, \n",
    "    #                       'X_villar_fit_reduced_chi2' : np.nan,\n",
    "    #                       'Y_villar_fit_amplitude' : np.nan, \n",
    "    #                       'Y_villar_fit_baseline' : np.nan,\n",
    "    #                       'Y_villar_fit_peak_time' : np.nan, \n",
    "    #                       'Y_villar_fit_rise_time' : np.nan,\n",
    "    #                       'Y_villar_fit_fall_time' : np.nan, \n",
    "    #                       'Y_villar_fit_plateau_slope' : np.nan,\n",
    "    #                       'Y_villar_fit_plateau_duration' : np.nan,\n",
    "    #                       'Y_villar_fit_reduced_chi2' : np.nan\n",
    "    #                      }, ignore_index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
