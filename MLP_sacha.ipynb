{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c0cbd734",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading YSE+ZTF SNANA-style data files from directory:  spec_yse_dr1\n",
      "int32 int64\n",
      "(247, 2) (247, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-175-a99056277c40>:49: FutureWarning: Index.__xor__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__xor__.  Use index.symmetric_difference(other) instead\n",
      "  weird = list(df_real_truths.index ^ set(b))\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from read_yse_ztf_snana_dir import read_YSE_ZTF_snana_dir\n",
    "\n",
    "snid_list, meta_list, yse_ztf_fp_df_list = read_YSE_ZTF_snana_dir('spec_yse_dr1')\n",
    "real_data = pd.DataFrame(pd.read_csv('Real_Data.csv'))\n",
    "\n",
    "# hyperparameters\n",
    "max_iter = 500\n",
    "stopping = False\n",
    "alpha = 0.0001\n",
    "random_state = 42\n",
    "\n",
    "# extracting the IDs that have sufficient information \n",
    "truth_ids = list(real_data['ObjectID'])\n",
    "\n",
    "columns = ['object_id', 'transient_spec_class']\n",
    "\n",
    "specs = []\n",
    "for dic in meta_list:\n",
    "    spec = dic['transient_spec_class']\n",
    "    specs.append(spec)\n",
    "\n",
    "p = dict(zip(snid_list, specs))\n",
    "ground_truth_dict = dict(zip(snid_list, specs))\n",
    "ground_truth = pd.DataFrame(zip(snid_list, specs), columns=columns)\n",
    "    \n",
    "# extracting the spec labels corresponding to the truth ids\n",
    "labels = []\n",
    "for item in ground_truth_dict.keys():\n",
    "    if item in truth_ids:\n",
    "        labels.append(ground_truth_dict[item])\n",
    "\n",
    "real_truths = zip(truth_ids, labels)\n",
    "df_real_truths = pd.DataFrame(real_truths, columns=['id', 'class'])\n",
    "\n",
    "# remove weird classes\n",
    "# df_real_truths = df_real_truths.drop('SNIa-CSM', axis=0)\n",
    "df_real_truths = df_real_truths[~df_real_truths['class'].isin(['SNIa-CSM', 'SNIIP', 'SNIIn', \\\n",
    "            'SNIa-91T-like', 'SNIa-SC', 'SNIax[02cx-like]', 'SLSN-II', 'SNIIb', 'SLSN-I', 'SNIb/c', 'SNIc-BL'])]\n",
    "\n",
    "b = [x for x in range(df_real_truths.index[0], df_real_truths.index[-1] + 1)]\n",
    "a = set(df_real_truths.index)\n",
    "weird = list(df_real_truths.index ^ set(b))\n",
    "print(np.array(weird).dtype, real_data.index.dtype)\n",
    "\n",
    "# remove rows in real_data.csv that correspond to the removed weird classes\n",
    "real_data_rem = real_data[~real_data.index.isin(weird)]\n",
    "\n",
    "# remove the object ID column from real_data\n",
    "df_real_data = real_data_rem.drop('ObjectID', axis=1)\n",
    "\n",
    "# print(labels.to_string(index=False))\n",
    "\n",
    "for i in range(len(df_real_truths)):\n",
    "    d = df_real_truths.iloc[i]\n",
    "    if d['class'] == 'SNIb' or d['class'] == 'SNIc':\n",
    "        d['class'] = 'SNIbc'\n",
    "\n",
    "labels = df_real_truths['class']\n",
    "\n",
    "print(df_real_truths.shape, df_real_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920dbaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f26c67cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51154, 2) (51154, 16)\n"
     ]
    }
   ],
   "source": [
    "snIa = pd.DataFrame(pd.read_csv('SNIa_sims.csv'))\n",
    "snIbc = pd.DataFrame(pd.read_csv('SNIbc_sims.csv'))\n",
    "snII = pd.DataFrame(pd.read_csv('SNII_sims.csv'))\n",
    "\n",
    "train_data = pd.concat([snIa, snIbc, snII])\n",
    "\n",
    "# extracting the IDs that have sufficient information \n",
    "train_ids = list(train_data['ObjectID'])\n",
    "\n",
    "columns = ['object_id', 'transient_spec_class']\n",
    "\n",
    "specs = []\n",
    "for dic in meta_list:\n",
    "    spec = dic['transient_spec_class']\n",
    "    specs.append(spec)\n",
    "\n",
    "p = dict(zip(snid_list, specs))\n",
    "ground_truth_dict_train = dict(zip(snid_list, specs))\n",
    "ground_truth_train = pd.DataFrame(zip(snid_list, specs), columns=columns)\n",
    "\n",
    "train_labels = ['SNIa']*len(snIa) + ['SNII']*len(snIbc) + ['SNIbc']*len(snII)\n",
    "\n",
    "train_truths = zip(train_ids, train_labels)\n",
    "df_train_truths = pd.DataFrame(train_truths, columns=['id', 'class'])\n",
    "\n",
    "# remove weird classes\n",
    "# df_real_truths = df_real_truths.drop('SNIa-CSM', axis=0)\n",
    "'''\n",
    "df_train_truths = df_train_truths[~df_train_truths['class'].isin(['SNIa-CSM', 'SNIIP', 'SNIIn', \\\n",
    "            'SNIa-91T-like', 'SNIa-SC', 'SNIax[02cx-like]', 'SLSN-II', 'SNIIb', 'SLSN-I', 'SNIb/c', 'SNIc-BL'])]\n",
    "\n",
    "b = [x for x in range(df_train_truths.index[0], df_train_truths.index[-1] + 1)]\n",
    "a = set(df_train_truths.index)\n",
    "weird = list(df_train_truths.index ^ set(b))\n",
    "print(np.array(weird).dtype, train_data.index.dtype)\n",
    "'''\n",
    "\n",
    "# remove rows in real_data.csv that correspond to the removed weird classes\n",
    "#train_data_rem = real_data[~train_data.index.isin(weird)]\n",
    "train_data_rem = train_data\n",
    "\n",
    "# remove the object ID column from real_data\n",
    "df_train_data = train_data_rem.drop('ObjectID', axis=1)\n",
    "train_labels = df_train_truths['class']\n",
    "\n",
    "print(df_train_truths.shape, df_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "99febf84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy, no ppca:  0.5262149587520037\n",
      "testing accuracy, no ppca:  0.5060728744939271\n"
     ]
    }
   ],
   "source": [
    "'''SciKit Learn MLP Classifier on all dimensions'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_real_data, labels, stratify=labels)\n",
    "\n",
    "X_test = df_real_data\n",
    "y_test = labels\n",
    "\n",
    "X_train = df_train_data\n",
    "y_train = train_labels\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), random_state=1, max_iter=300, early_stopping=True).fit(X_train, y_train)\n",
    "\n",
    "# print(clf.predict_proba(X_test).shape)\n",
    "\n",
    "pred_labels = clf.predict(X_test)\n",
    "\n",
    "# print the confusion matrix (should be k by k, where k = 11)\n",
    "conf = confusion_matrix(y_test, pred_labels, normalize='all')\n",
    "# print(conf)\n",
    "\n",
    "print('training accuracy, no ppca: ', clf.score(X_train, y_train))\n",
    "print('testing accuracy, no ppca: ', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae276c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "988a63ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy, ppca:  0.7257496969933925\n",
      "testing accuracy, ppca:  0.44534412955465585\n",
      "y_train Counter({'SNIa': 19004, 'SNII': 16874, 'SNIbc': 15276})\n",
      "pred_labels Counter({'SNIa': 140, 'SNII': 78, 'SNIbc': 29})\n",
      "true_labels Counter({'SNIa': 183, 'SNII': 53, 'SNIbc': 11})\n"
     ]
    }
   ],
   "source": [
    "'''SciKit Learn MLP Classifier on reduced dimensions'''\n",
    "\n",
    "from PPCA import applyppca\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# fakes_df = pd.read_csv(\"./SNIa_sims.csv\", index_col=0)\n",
    "\n",
    "pca_num = 8\n",
    "\n",
    "ss = StandardScaler()\n",
    "smaller = ss.fit_transform(df_real_data)\n",
    "real_small = pd.DataFrame(smaller)\n",
    "\n",
    "ss = StandardScaler()\n",
    "smaller = ss.fit_transform(df_train_data)\n",
    "fake_small = pd.DataFrame(smaller)\n",
    "\n",
    "W, var, pcs2_X_real, pcs2_X_fake, score2, coeff2 = applyppca(dataset_real=real_small, dataset_fakes=fake_small, pca_num=pca_num)\n",
    "\n",
    "# must transpose output of applyppca\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pcs2_X_real.T, labels)\n",
    "\n",
    "X_test = pcs2_X_real.T\n",
    "y_test = labels\n",
    "\n",
    "X_train = pcs2_X_fake.T\n",
    "y_train = train_labels\n",
    "\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(100,100), random_state=1, max_iter=500, early_stopping=True).fit(X_train, y_train)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,100), random_state=random_state, max_iter=max_iter, early_stopping=stopping, alpha=alpha).fit(X_train, y_train)\n",
    "\n",
    "# print(\"Y_train\", y_train.values)\n",
    "# print(\"probas\", clf.predict_proba(X_test))\n",
    "# print(\"counter\", Counter(y_train))\n",
    "pred_labels = clf.predict(X_test)\n",
    "\n",
    "# print the confusion matrix (should be k by k, where k = 11)\n",
    "conf = confusion_matrix(y_test, pred_labels)\n",
    "\n",
    "# compare the predicted and test labels\n",
    "compare = zip(np.array(y_test), pred_labels)\n",
    "\n",
    "df_compare = pd.DataFrame(compare, columns=['truths', 'predicted'])\n",
    "#print(df_compare)\n",
    "\n",
    "print('training accuracy, ppca: ', clf.score(X_train, y_train))\n",
    "print('testing accuracy, ppca: ', clf.score(X_test, y_test))\n",
    "\n",
    "# y_pred = model.predict(x_test)\n",
    "print(\"acc\", accuracy_score(y_true=labels, y_pred=pred_labels))\n",
    "\n",
    "print(\"y_train\", Counter(y_train))\n",
    "print(\"pred_labels\", Counter(pred_labels))\n",
    "print(\"true_labels\", Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cd9e0f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.08502024291497975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"acc\", accuracy_score(y_true=labels, y_pred=pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3bb679dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy, original pca:  0.7367556789302889\n",
      "testing accuracy, original pca:  0.08502024291497975\n"
     ]
    }
   ],
   "source": [
    "'''SciKit Learn MLP test on original PCA'''\n",
    "\n",
    "from PPCA import applypca\n",
    "\n",
    "# apply the pca\n",
    "# pca_num=6\n",
    "\n",
    "\n",
    "\n",
    "pca, pcs_X_real, pcs_X_fakes, score, coeff = applypca(dataset_real = df_real_data, dataset_fakes=df_train_data, pca_num=pca_num)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pcs_X_real, labels)\n",
    "\n",
    "X_test = pcs_X_real\n",
    "y_test = labels\n",
    "\n",
    "X_train = pcs_X_fakes\n",
    "y_train = train_labels\n",
    "\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(100,100,100,100), random_state=1, max_iter=500, early_stopping=True).fit(X_train, y_train)\n",
    "\n",
    "# print(\"proba\", clf.predict_proba(X_test))\n",
    "\n",
    "pred_labels = clf.predict(X_test)\n",
    "\n",
    "# print the confusion matrix (should be k by k, where k = 11)\n",
    "conf = confusion_matrix(y_test, pred_labels)\n",
    "\n",
    "# compare the predicted and test labels\n",
    "compare = zip(np.array(y_test), pred_labels)\n",
    "\n",
    "df_compare = pd.DataFrame(compare, columns=['truths', 'predicted'])\n",
    "# print(df_compare)\n",
    "\n",
    "\n",
    "print('training accuracy, original pca: ', clf.score(X_train, y_train))\n",
    "print('testing accuracy, original pca: ', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "52809418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter Counter({'SNIa': 19004, 'SNII': 16874, 'SNIbc': 15276})\n",
      "counter Counter({'SNII': 140, 'SNIbc': 106, 'SNIa': 1})\n",
      "counter Counter({'SNIa': 183, 'SNII': 53, 'SNIbc': 11})\n",
      "    truths predicted\n",
      "0     SNIa     SNIbc\n",
      "1     SNII     SNIbc\n",
      "2     SNIa      SNII\n",
      "3     SNIa     SNIbc\n",
      "4     SNII      SNII\n",
      "..     ...       ...\n",
      "242   SNII     SNIbc\n",
      "243   SNIa      SNII\n",
      "244   SNIa      SNII\n",
      "245   SNIa     SNIbc\n",
      "246   SNIa     SNIbc\n",
      "\n",
      "[247 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"counter\", Counter(y_train))\n",
    "print(\"counter\", Counter(pred_labels))\n",
    "print(\"counter\", Counter(labels))\n",
    "print(df_compare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e2e55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036dbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad822c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865009ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
